# Autogenerated with SMOP 
from smop.core import *
# OSVR/admm.m

    
@function
def admm(A=None,e=None,lambda_=None,mu=None,varargin=None,*args,**kwargs):
    varargin = admm.varargin
    nargin = admm.nargin

    # admm: Alternative Direction Method of Multipliers solver
# Author: Rui Zhao 2015.11.13.
# Reference: Boyd 2011, Distributed optimization and statistical learning via the alternating direction method of multipliers
    
    # model = admm(Problem, mu) solve the following optimization problem using
# ADMM updates
    
    #      minimize_{x,z}  0.5*x'*L*x + u'*((z)_+).^p
#      s.t. z = Ax + e
    
    # Input:
#       A: data matrix
#       e: label vector
#       lambda: a vector or a scalar specifying the diagonal entries of L
#       mu: a vector storing weights
# 
# Output: 
#       model.w is the model parameter without bias term
#       model.b is the model parameter bias term
# 
# [model,history,z] = admm(Problem, mu) also returns 
#       history, a struct storing the ADMM update history and
#       z, auxilary variables introduced by ADMM
# 
# [model,history,z] = admm(Problem, mu, varargin) support optional input arguments:
#       'rho': value of augmented Lagrangian multipliers
#       'max_iter': maximum number iterations allowed before convergence
#       'bias': 1 if add bias term to features and 0 otherwise
#       'option': 1: use hingle loss i.e. p = 1, 2: use squared hinge loss i.e. p = 2
#       'ABSTOL': absolute tolerence value used to decide convergence
#       'RELTOL': relative tolerence value used to decide convergence
#       'early_stop': 1: stop update of x if meet convergence criteria; 0 otherwise
    
    # Example: 
#       load('angry.mat');
#       [model,history,z] = admm(A, e, lambda, mu, 'rho', rho, 'max_iter', max_iter, 'option', option);
# 
# Example:
# admm() can be used to solve C-SVM with following formulation
# the primal problem of L2 regularized hinge or squared hinge loss linear C-SVM using ADMM
# SVM formulation:
#       \min_{w,b}  0.5*||w||^2 + \sum_{n=1}^N max(0,1-y_n(w^T x_n + b))^p
# Reference:
    
    # specify default values
    rho=1
# OSVR/admm.m:47
    max_iter=100
# OSVR/admm.m:48
    bias=0
# OSVR/admm.m:49
    option=1
# OSVR/admm.m:50
    ABSTOL=0.001
# OSVR/admm.m:51
    RELTOL=0.001
# OSVR/admm.m:52
    early_stop=0
# OSVR/admm.m:53
    for argidx in arange(1,nargin - 4,2).reshape(-1):
        if 'rho' == varargin[argidx]:
            rho=varargin[argidx + 1]
# OSVR/admm.m:57
        else:
            if 'max_iter' == varargin[argidx]:
                max_iter=varargin[argidx + 1]
# OSVR/admm.m:59
            else:
                if 'bias' == varargin[argidx]:
                    bias=varargin[argidx + 1]
# OSVR/admm.m:61
                else:
                    if 'option' == varargin[argidx]:
                        option=varargin[argidx + 1]
# OSVR/admm.m:63
                    else:
                        if 'ABSTOL' == varargin[argidx]:
                            ABSTOL=varargin[argidx + 1]
# OSVR/admm.m:65
                        else:
                            if 'RELTOL' == varargin[argidx]:
                                RELTOL=varargin[argidx + 1]
# OSVR/admm.m:67
                            else:
                                if 'early_stop' == varargin[argidx]:
                                    early_stop=varargin[argidx + 1]
# OSVR/admm.m:69
    
    # initialize data
    N,D=size(A,nargout=2)
# OSVR/admm.m:74
    
    assert_(length(e) == N,'Number of labels does not match data dimension')
    A=matlabarray(cat(A,ones(N,bias)))
# OSVR/admm.m:76
    assert_(numel(lambda_) == length(lambda_),'lambda must be a scalar or a vector')
    lambda_=matlabarray(cat([ravel(lambda_)],[ones(bias,1)]))
# OSVR/admm.m:78
    lambda_=diag(lambda_)
# OSVR/admm.m:79
    # initialize variables
    x=zeros(D + bias,1)
# OSVR/admm.m:82
    
    z=zeros(N,1)
# OSVR/admm.m:83
    
    y=zeros(N,1)
# OSVR/admm.m:84
    
    # mu = gamma*mu; # change the values if you want to assign different weights to different samples
    loss=dot(A,x) + e
# OSVR/admm.m:86
    # different loss functions
    loss[loss < 0]=0
# OSVR/admm.m:89
    if option == 1:
        f=dot(dot(dot(0.5,(x.T)),lambda_),x) + dot(mu.T,loss)
# OSVR/admm.m:91
    else:
        if option == 2:
            f=dot(dot(dot(0.5,(x.T)),lambda_),x) + dot(mu.T,(loss ** 2))
# OSVR/admm.m:93
    
    # main iterations
    r_norm=zeros(1,max_iter)
# OSVR/admm.m:97
    s_norm=zeros(1,max_iter)
# OSVR/admm.m:98
    eps_pri=zeros(1,max_iter)
# OSVR/admm.m:99
    eps_dual=zeros(1,max_iter)
# OSVR/admm.m:100
    obj_res=zeros(1,max_iter)
# OSVR/admm.m:101
    obj=zeros(1,max_iter)
# OSVR/admm.m:102
    x_change=zeros(1,max_iter)
# OSVR/admm.m:103
    x_flag=0
# OSVR/admm.m:103
    y_change=zeros(1,max_iter)
# OSVR/admm.m:104
    z_change=zeros(1,max_iter)
# OSVR/admm.m:105
    for it in arange(1,max_iter).reshape(-1):
        # update x
        if logical_not(x_flag):
            x_old=copy(x)
# OSVR/admm.m:110
            if it == 1:
                H=dot(dot(1 / rho,lambda_),eye(D + bias)) + dot(A.T,A)
# OSVR/admm.m:113
                U,S,V=svd(H,0,nargout=3)
# OSVR/admm.m:114
                Sinv=diag(1.0 / diag(S))
# OSVR/admm.m:115
                Hinv=dot(dot(dot(V,Sinv),(U.T)),(A.T))
# OSVR/admm.m:116
            q=(z - y / rho - e)
# OSVR/admm.m:118
            x=dot(Hinv,q)
# OSVR/admm.m:119
        x_change[it]=norm(x - x_old)
# OSVR/admm.m:121
        if x_change[it] < ABSTOL and early_stop:
            x_flag=1
# OSVR/admm.m:124
        # update z
        z_old=copy(z)
# OSVR/admm.m:128
        Ax=dot(A,x)
# OSVR/admm.m:129
        loss=Ax + e
# OSVR/admm.m:130
        if option == 1:
            theta=y / rho + loss - dot(0.5 / rho,mu)
# OSVR/admm.m:132
            a=mu / 2 / rho
# OSVR/admm.m:133
            z[theta >= 0]=max(theta[theta >= 0] - a[theta >= 0],0)
# OSVR/admm.m:134
            z[theta < 0]=min(theta[theta < 0] + a[theta < 0],0)
# OSVR/admm.m:135
        else:
            if option == 2:
                theta=y / rho + loss
# OSVR/admm.m:137
                z[theta >= 0]=multiply(rho,theta[theta >= 0]) / (rho + dot(2,mu[theta >= 0]))
# OSVR/admm.m:138
                z[theta < 0]=theta[theta < 0]
# OSVR/admm.m:139
        z_change[it]=norm(z - z_old)
# OSVR/admm.m:141
        dy=dot(rho,(loss - z))
# OSVR/admm.m:144
        y=y + dy
# OSVR/admm.m:145
        y_change[it]=norm(dy)
# OSVR/admm.m:146
        # objective convergence: check the change of objective function
        loss[loss < 0]=0
# OSVR/admm.m:150
        if option == 1:
            f_new=dot(dot(dot(0.5,(x.T)),lambda_),x) + dot(mu.T,loss)
# OSVR/admm.m:152
        else:
            if option == 2:
                f_new=dot(dot(dot(0.5,(x.T)),lambda_),x) + dot(mu.T,(loss ** 2))
# OSVR/admm.m:154
        obj[it]=f_new
# OSVR/admm.m:156
        obj_res[it]=f_new - f
# OSVR/admm.m:157
        f=copy(f_new)
# OSVR/admm.m:158
        r_norm[it]=norm(dy / rho)
# OSVR/admm.m:160
        s_norm[it]=norm(dot(rho,(z - z_old)))
# OSVR/admm.m:161
        eps_pri[it]=dot(sqrt(N),ABSTOL) + dot(RELTOL,max(cat(norm(Ax),norm(- z),norm(e))))
# OSVR/admm.m:162
        eps_dual[it]=dot(sqrt(D + bias),ABSTOL) + dot(RELTOL,norm(y))
# OSVR/admm.m:163
        if (r_norm[it] < eps_pri[it] and s_norm[it] < eps_dual[it]):
            break
        if abs(r_norm[it]) < ABSTOL and abs(obj_res[it]) < ABSTOL:
            break
    
    # save results
    model.w = copy(x[1:D])
# OSVR/admm.m:173
    model.b = copy(dot(bias,x[D + bias]))
# OSVR/admm.m:174
    history.iter = copy(it)
# OSVR/admm.m:175
    history.r_norm = copy(r_norm[1:it])
# OSVR/admm.m:176
    history.s_norm = copy(s_norm[1:it])
# OSVR/admm.m:177
    history.eps_pri = copy(eps_pri[1:it])
# OSVR/admm.m:178
    history.eps_dual = copy(eps_dual[1:it])
# OSVR/admm.m:179
    history.obj_res = copy(obj_res[1:it])
# OSVR/admm.m:180
    history.obj = copy(obj[1:it])
# OSVR/admm.m:181
    history.rho = copy(rho)
# OSVR/admm.m:182
    history.x_change = copy(x_change[1:it])
# OSVR/admm.m:183
    history.y_change = copy(y_change[1:it])
# OSVR/admm.m:184
    history.z_change = copy(z_change[1:it])
# OSVR/admm.m:185
    return model,history,z
    
if __name__ == '__main__':
    pass
    